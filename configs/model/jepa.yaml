_target_: src.models.jepa_module.JEPAModule

encoder:
  _target_: src.models.components.vision_transformer.VisionTransformer
  patch_size: # Tuple of the patch size 
  - 16 # Patch size in the Time dimension (height)
  - 16 # Patch size in the Frequency dimension (width)
  in_chans: 1
  embed_dim: 768
  depth: 12
  num_heads: 12
  mlp_ratio: 4.

predictor:
  _target_: src.models.components.vision_transformer.VisionTransformerPredictor
  num_sources: 4
  embed_dim: ${model.encoder.embed_dim}
  depth: 6
  num_heads: 12
  mlp_ratio: 4.

criterion:
  _target_: src.models.components.loss.Loss
  loss_type: norm_mse
  norm_pix_loss: true

# optimizer:
#   _target_: pytorch_optimizer.AdamW
#   _partial_: true
#   lr: 0.0003
#   weight_decay: 0.05
#   betas:
#     - 0.9
#     - 0.95

optimizer:
  _target_: pytorch_optimizer.AdEMAMix
  _partial_: true
  lr: 0.0003
  betas:
    - 0.9
    - 0.999
    - 0.9999
  weight_decay: 0.05
  alpha: 10
  # t_alpha_beta3: total number of steps, is defined in the LightningModule's configure_optimizers method
  



lr_scheduler:
  _target_: src.optimizers.warmup_cosine.WarmupCosineScheduler
  _partial_: true
  warmup_steps: 2000
  start_lr: 1e-6
  ref_lr: 1e-3
  final_lr: 1e-5

# compile model for faster training with pytorch 2.0
compile: True # Does not work on my windows machine.
